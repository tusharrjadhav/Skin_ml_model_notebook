{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Skin Cancer Classification using Transfer Learning (InceptionResNetV2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook is adapted to run on Kaggle Notebooks. Ensure that the dataset is uploaded or accessible in `/kaggle/input` and the outputs are saved to `/kaggle/working`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from tensorflow.keras import layers, Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ensure Data is in Proper Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define paths for dataset and working directory (Kaggle environment)\n",
        "DATASET_PATH = \"/kaggle/input/skin-cancer-mnist-ham10000\"\n",
        "WORKING_PATH = \"/kaggle/working\"\n",
        "IMAGE_PATH = os.path.join(WORKING_PATH, \"HAM_images\")\n",
        "DATASET_CSV_PATH = os.path.join(DATASET_PATH, \"HAM10000_metadata.csv\")\n",
        "\n",
        "# Ensure working directory exists\n",
        "os.makedirs(WORKING_PATH, exist_ok=True)\n",
        "\n",
        "# Combine the two parts of image data into one folder\n",
        "part1_image_dir = os.path.join(DATASET_PATH, \"HAM10000_images_part_1\")\n",
        "part2_image_dir = os.path.join(DATASET_PATH, \"HAM10000_images_part_2\")\n",
        "\n",
        "os.makedirs(IMAGE_PATH, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(part1_image_dir):\n",
        "    shutil.copy(os.path.join(part1_image_dir, filename), IMAGE_PATH)\n",
        "\n",
        "for filename in os.listdir(part2_image_dir):\n",
        "    shutil.copy(os.path.join(part2_image_dir, filename), IMAGE_PATH)\n",
        "\n",
        "print(f\"Total images: {len(os.listdir(IMAGE_PATH))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Process Dataset Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_labels = pd.read_csv(DATASET_CSV_PATH)\n",
        "mapping = {\n",
        "    'akiec': 'AKIEC',\n",
        "    'bcc': 'BCC',\n",
        "    'bkl': 'BKL',\n",
        "    'df': 'DF',\n",
        "    'mel': 'MEL',\n",
        "    'nv': 'NV',\n",
        "    'vasc': 'VASC'\n",
        "}\n",
        "df_labels['label'] = df_labels['dx'].map(mapping)\n",
        "df_labels.rename(columns={'image_id': 'image'}, inplace=True)\n",
        "df_labels.set_index('image', inplace=True)\n",
        "print(df_labels.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.countplot(data=df_labels, x='label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Dataset for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create folders for each label in the working directory\n",
        "DATASET_DIR = os.path.join(WORKING_PATH, \"HAM_Dataset\")\n",
        "os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "\n",
        "labels = df_labels['label'].unique()\n",
        "\n",
        "for label in labels:\n",
        "    os.makedirs(os.path.join(DATASET_DIR, label), exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(IMAGE_PATH):\n",
        "    image_id = filename.split('.')[0]\n",
        "    if image_id in df_labels.index:\n",
        "        label = df_labels.loc[image_id, 'label']\n",
        "        shutil.move(os.path.join(IMAGE_PATH, filename), os.path.join(DATASET_DIR, label, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Augmentation and Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_gen = ImageDataGenerator(\n",
        "    rescale=1/255.0,\n",
        "    validation_split=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=30\n",
        ")\n",
        "\n",
        "train_gen = image_gen.flow_from_directory(\n",
        "    DATASET_DIR,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "valid_gen = image_gen.flow_from_directory(\n",
        "    DATASET_DIR,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained model\n",
        "base_model = InceptionResNetV2(include_top=False, input_shape=(224, 224, 3))\n",
        "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output_layer = layers.Dense(len(labels), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    epochs=10,\n",
        "    steps_per_epoch=train_gen.samples // train_gen.batch_size,\n",
        "    validation_steps=valid_gen.samples // valid_gen.batch_size\n",
        ")\n",
        "model.save(os.path.join(WORKING_PATH, \"skin_cancer_model.h5\"))"
        "model.save(os.path.join(WORKING_PATH, "skin_cancer_model.keras"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
